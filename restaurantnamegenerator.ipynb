{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4fdd810-711e-4868-91c2-cc48189ec1cf",
   "metadata": {},
   "source": [
    "# Importing OpenAI API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c01546c2-3fec-4e1f-abec-9d2c5657f08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad4bcd9-50b2-4dc4-8f0b-6fb853dd85df",
   "metadata": {},
   "source": [
    "# Import OpenAI from langchain and set temprature when it's 0 it is safest model andnot very innovative and 1 so model take risk and innovative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "daeb9234-4128-4dbe-8899-9fd7ee9752df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\parjita\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\"La Bella Vita\" \n"
     ]
    }
   ],
   "source": [
    "# from langchain.llms import OpenAI\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "llm = OpenAI(temperature=0.6)\n",
    "name = llm(\"I want to open a restaurant for Italian Food. Suggest a fency name for that\")\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f692f87b-5940-4b8e-8ae5-cbae949a5457",
   "metadata": {},
   "source": [
    "# Import prompt table and set input and prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6725d807-c614-4bfc-8245-e6e145256abe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I want to open a restaurant for maxican food.Suggest a fency name for that'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables = ['cusine'],\n",
    "    template = \"I want to open a restaurant for {cusine} food.Suggest a fency name for that\"\n",
    ")\n",
    "\n",
    "prompt_template_name.format(cusine = \"maxican\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3824a2a-8196-49ae-96d2-10c584a07f38",
   "metadata": {},
   "source": [
    "# Import LLMChain and use chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58c86af0-05ea-4b92-b9c7-2dc414d7fd47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\parjita\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  warn_deprecated(\n",
      "C:\\Users\\parjita\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\n\"Stateside Eats\" '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template_name)\n",
    "chain.run(\"American\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489ade06-e13d-4c90-b578-7c6375802f26",
   "metadata": {},
   "source": [
    "# Simple Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dad108e2-69e1-49e7-8cab-dc730b5263cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables = ['cusine'],\n",
    "    template = \"I want to open a restaurant for {cusine} food.Suggest a fency name for that\"\n",
    ")\n",
    "\n",
    "name_chain = LLMChain(llm=llm, prompt=prompt_template_name)\n",
    "\n",
    "prompt_template_items = PromptTemplate(\n",
    "    input_variables = ['restaurant name'],\n",
    "    template = \"Suggest some menu items for {restaurant_name},Return it as a coma seperate\"\n",
    ")\n",
    "\n",
    "food_items_chain = LLMChain(llm=llm, prompt=prompt_template_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ed277f0-0b42-475c-87fe-dc08f5dd71e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Appetizers: \n",
      "- Queso Fundido (melted cheese with chorizo and tortilla chips)\n",
      "- Guacamole and Chips\n",
      "- Taquitos (fried rolled tortillas filled with chicken or beef)\n",
      "- Nachos Supreme (topped with beans, cheese, sour cream, guacamole, and choice of meat)\n",
      "\n",
      "2. Tacos: \n",
      "- Carne Asada (grilled marinated steak)\n",
      "- Carnitas (slow-cooked pork)\n",
      "- Pollo (grilled chicken)\n",
      "- Al Pastor (marinated pork with pineapple)\n",
      "- Vegetarian (grilled vegetables)\n",
      "\n",
      "3. Burritos: \n",
      "- Carne Asada (grilled marinated steak)\n",
      "- Pollo (grilled chicken)\n",
      "- Carnitas (slow-cooked pork)\n",
      "- Vegetarian (grilled vegetables)\n",
      "- Shrimp (grilled or sautéed)\n",
      "\n",
      "4. Enchiladas: \n",
      "- Cheese (with red or green sauce)\n",
      "- Chicken (with red or green sauce)\n",
      "- Beef (with red or green sauce)\n",
      "- Spinach and Mushroom (with green sauce)\n",
      "\n",
      "5. Fajitas: \n",
      "- Chicken (grilled chicken with sautéed peppers and onions)\n",
      "- Steak (grilled marinated steak with\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "chain = SimpleSequentialChain(chains = [name_chain,food_items_chain])\n",
    "response = chain.run(\"Maxican\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2eb65033-e39e-46ba-8503-63237d003b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.7)\n",
    "\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables = ['cusine'],\n",
    "    template = \"I want to open a restaurant for {cusine} food.Suggest a fency name for that\"\n",
    ")\n",
    "\n",
    "name_chain = LLMChain(llm=llm, prompt=prompt_template_name, output_key=\"restaurant_name\")\n",
    "\n",
    "llm = OpenAI(temperature=0.7)\n",
    "\n",
    "prompt_template_items = PromptTemplate(\n",
    "    input_variables = ['restaurant name'],\n",
    "    template = \"Suggest some menu items for {restaurant_name}.\"\n",
    ")\n",
    "\n",
    "food_items_chain = LLMChain(llm=llm, prompt=prompt_template_items, output_key=\"menu_items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8ec0322d-b55e-4e32-826b-2b3b04a3de95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\parjita\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cusine': 'Arabic',\n",
       " 'restaurant_name': '\\n\\n\"Al-Fawar\" (meaning \"The Fountain\") ',\n",
       " 'menu_items': '\\n\\n1. Shawarma Platter: A platter of tender, marinated chicken or beef shawarma served with rice, salad, and a side of hummus and pita bread.\\n\\n2. Mansaf: A traditional Jordanian dish made with lamb or chicken cooked in a yogurt sauce and served with rice and almonds.\\n\\n3. Falafel Wrap: Crispy chickpea fritters wrapped in pita bread with lettuce, tomatoes, pickles, and tahini sauce.\\n\\n4. Kebab Combo: A combination of grilled chicken, beef, and lamb kebabs served with rice, grilled vegetables, and a side of tzatziki sauce.\\n\\n5. Fattoush Salad: A refreshing salad made with mixed greens, tomatoes, cucumber, radish, and crispy pita chips, dressed in a tangy lemon and olive oil dressing.\\n\\n6. Maqlooba: A flavorful dish made with layers of rice, vegetables, and your choice of chicken or beef, cooked in a rich tomato-based sauce.\\n\\n7. Hummus Trio: A sampler platter of three different types of hummus - traditional, roasted red pepper, and garlic - served with pita bread.\\n\\n8. Tabouli: A fresh and healthy salad made with'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "\n",
    "chain = SequentialChain(\n",
    "    chains = [name_chain, food_items_chain],\n",
    "    input_variables = ['cusine'],\n",
    "    output_variables = ['restaurant_name','menu_items']\n",
    ")\n",
    "\n",
    "chain({'cusine':'Arabic'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45abd4ea-8222-426e-b42d-ff866842aa00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
